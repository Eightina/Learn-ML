{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "## 1. k-means聚类的缺点\r\n",
                "2维k-means模型的本质是，它以每个簇的中心为圆心，簇中点到簇中心点的欧氏距离最大值为半径画一个圆。这个圆硬性的将训练集进行截断。而且，k-means要求这些簇的形状必须是圆形的。因此，k-means模型拟合出来的簇（圆形）与实际数据分布（可能是椭圆）差别很大，经常出现多个圆形的簇混在一起，相互重叠。总的来说，k-means存在两个缺点，使得它对许多数据集（特别是低维数据集）的拟合效果不尽如人意：\r\n",
                "* 类的形状不够灵活，拟合结果与实际相差较大，精度有限。\r\n",
                "* 样本属于每一个簇的概率是定性的，只有是与否，不能输出概率值。应用中缺少鲁棒性。\r\n",
                "\r\n",
                "\r\n",
                "## 2. 高斯混合模型\r\n",
                "  高斯混合模型（GMM）可以看做是k-means模型的一个优化。它既是一种工业界常用的技术手段，也是一种生成式模型。高斯混合模型试图找到多维高斯模型概率分布的混合表示，从而拟合出任意形状的数据分布。在最简单的场景中，GMM可以用与k-means相同的方式进行聚类。"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "----"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 1. 基于质心的算法\r\n",
                "### K均值算法\r\n",
                "#### K均值算法的优点：\r\n",
                "* 是解决聚类问题的一种经典算法，简单、快速\r\n",
                "* 对处理大数据集，该算法保持可伸缩性和高效性\r\n",
                "* 当簇接近高斯分布时，它的效果较好。\r\n",
                "#### K均值算法的缺点：\r\n",
                "* 在簇的平均值可被定义的情况下才能使用，可能不适用于某些应用；\r\n",
                "* 在 K-means 算法中 K 是事先给定的，这个 K 值的选定是非常难以估计的。很多时候，事先并不知道给定的数据集应该分成多少个类别才最合适；\r\n",
                "* 在 K-means 算法中，首先需要根据初始聚类中心来确定一个初始划分，然后对初始划分进行优化。这个初始聚类中心的选择对聚类结果有较大的影响，一旦初始值选择的不好，可能无法得到有效的聚类结果；\r\n",
                "* 算法需要不断地进行样本分类调整，不断地计算调整后的新的聚类中心，因此当数据量非常大时，算法的时间开销是非常大的；\r\n",
                "* 若簇中含有异常点，将导致均值偏离严重（即:对噪声和孤立点数据敏感）；\r\n",
                "* 不适用于发现非凸形状的簇或者大小差别很大的簇。\r\n",
                "\r\n",
                "模糊c均值聚类\r\n",
                "https://blog.csdn.net/lyxleft/article/details/88964494\r\n",
                "\r\n",
                "用三角不等式加速的K均值算法\r\n",
                "https://blog.csdn.net/haimengao/article/details/29553767\r\n",
                "\r\n",
                "----\r\n",
                "\r\n",
                "## 2.层次聚类\r\n",
                "### BIRCH层次聚类\r\n",
                "#### BIRCH层次聚类的优点：\r\n",
                "* 节约内存，所有的样本都在磁盘上，CF Tree仅仅存了CF节点和对应的指针。\r\n",
                "* 聚类速度快，只需要一遍扫描训练集就可以建立CF Tree，CF Tree的增删改都很快。\r\n",
                "* 可以识别噪音点，还可以对数据集进行初步分类的预处理\r\n",
                "#### BIRCH层次聚类的缺点：\r\n",
                "* 由于CF Tree对每个节点的CF个数有限制，导致聚类的结果可能和真实的类别分布不同.\r\n",
                "* 对高维特征的数据聚类效果不好。此时可以选择Mini Batch K-Means\r\n",
                "* 如果数据集的分布簇不是类似于超球体，或者说不是凸的，则聚类效果不好。\r\n",
                "  \r\n",
                "https://blog.csdn.net/Mbx8X9u/article/details/78910496\r\n",
                "\r\n",
                "----\r\n",
                "\r\n",
                "## 3.基于概率分布的算法\r\n",
                "### EM算法 期望最大化算法\r\n",
                "https://blog.csdn.net/qq_17073497/article/details/81272704\r\n",
                "\r\n",
                "https://blog.csdn.net/qq_43468729/article/details/84952202\r\n",
                "\r\n",
                "----\r\n",
                "\r\n",
                "## 4.基于密度的算法\r\n",
                "### DBSCAN算法（Density-Based Spatial Clustering of Applications with Noise，具有噪声的基于密度的聚类方法）\r\n",
                "#### DBSCAN的优点：\r\n",
                "* 可以对任意形状的稠密数据集进行聚类，相对的，K-Means之类的聚类算法一般只适用于凸数据\r\n",
                "* 可以在聚类的同时发现异常点，对数据集中的异常点不敏感。\r\n",
                "* 聚类结果没有偏倚，相对的，K-Means之类的聚类算法初始值对聚类结果有很大影响。\r\n",
                "#### DBSCAN的缺点：\r\n",
                "* 如果样本集的密度不均匀、聚类间距差相差很大时，聚类质量较差，这时用DBSCAN聚类一般不适合。\r\n",
                "* 如果样本集较大时，聚类收敛时间较长，此时可以对搜索最近邻时建立的KD树或者球树进行规模限制来改进。\r\n",
                "* 调参相对于传统的K-Means之类的聚类算法稍复杂，主要需要对距离阈值，邻域样本数阈值MinPts联合调参，不同的参数组合对最后的聚类效果有较大影响。\r\n",
                "### OPTICS算法（Ordering points to identify the clustering structure，排序点来识别聚类结构）\r\n",
                "这个算法有效的解决了密度不同导致的聚类效果不好的问题。\r\n",
                "\r\n",
                "### Mean Shift算法 （均值漂移）\r\n",
                "基于核密度估计技术，是一种寻找概率密度函数极值点的算法\r\n",
                "\r\n",
                "https://blog.csdn.net/stesha_chen/article/details/88827010\r\n",
                "\r\n",
                "----\r\n",
                "\r\n",
                "## 5.基于图的算法\r\n",
                "### 谱聚类算法\r\n",
                "#### 谱聚类算法的优点\r\n",
                "* 当聚类的类别个数较小的时候，谱聚类的效果会很好，但是当聚类的类别个数较大的时候，则不建议使用谱聚类；\r\n",
                "* 谱聚类算法使用了降维的技术，所以更加适用于高维数据的聚类；\r\n",
                "* 谱聚类只需要数据之间的相似度矩阵，因此对于处理稀疏数据的聚类很有效。这点传统聚类算法（比如K-Means）很难做到\r\n",
                "* 谱聚类算法建立在谱图理论基础上，与传统的聚类算法相比，它具有能在任意形状的样本空间上聚类且收敛于全局最优解\r\n",
                "#### 谱聚类算法的缺点\r\n",
                "* 谱聚类对相似度图的改变和聚类参数的选择非常的敏感；\r\n",
                "* 谱聚类适用于均衡分类问题，即各簇之间点的个数相差不大，对于簇之间点个数相差悬殊的聚类问题，谱聚类则不适用；\r\n",
                "* \r\n",
                "https://blog.csdn.net/qq_24519677/article/details/82291867\r\n"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}