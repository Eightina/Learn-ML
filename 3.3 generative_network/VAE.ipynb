{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torchvision\r\n",
    "from torchvision import transforms\r\n",
    "from torchvision.utils import save_image\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Device configuration\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "\r\n",
    "# Create a directory if not exists\r\n",
    "sample_dir = 'samples'\r\n",
    "if not os.path.exists(sample_dir):\r\n",
    "    os.makedirs(sample_dir)\r\n",
    "\r\n",
    "# Hyper-parameters\r\n",
    "image_size = 784\r\n",
    "h_dim = 400\r\n",
    "z_dim = 20\r\n",
    "num_epochs = 15\r\n",
    "batch_size = 128\r\n",
    "learning_rate = 1e-3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# MNIST dataset\r\n",
    "dataset = torchvision.datasets.MNIST(root='../../data',\r\n",
    "                                     train=True,\r\n",
    "                                     transform=transforms.ToTensor(),\r\n",
    "                                     download=True)\r\n",
    "\r\n",
    "# Data loader\r\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset,\r\n",
    "                                          batch_size=batch_size, \r\n",
    "                                          shuffle=True)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# VAE model\r\n",
    "class VAE(nn.Module):\r\n",
    "    def __init__(self, image_size=784, h_dim=400, z_dim=20):\r\n",
    "        super(VAE, self).__init__()\r\n",
    "        self.fc1 = nn.Linear(image_size, h_dim)\r\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\r\n",
    "        self.fc3 = nn.Linear(h_dim, z_dim)\r\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim)\r\n",
    "        self.fc5 = nn.Linear(h_dim, image_size)\r\n",
    "        \r\n",
    "    def encode(self, x):\r\n",
    "        h = F.relu(self.fc1(x))\r\n",
    "        return self.fc2(h), self.fc3(h)\r\n",
    "    \r\n",
    "    def reparameterize(self, mu, log_var):\r\n",
    "        std = torch.exp(log_var/2)\r\n",
    "        eps = torch.randn_like(std)\r\n",
    "        return mu + eps * std\r\n",
    "\r\n",
    "    def decode(self, z):\r\n",
    "        h = F.relu(self.fc4(z))\r\n",
    "        return F.sigmoid(self.fc5(h))\r\n",
    "    \r\n",
    "    def forward(self, x):\r\n",
    "        mu, log_var = self.encode(x)\r\n",
    "        z = self.reparameterize(mu, log_var)\r\n",
    "        x_reconst = self.decode(z)\r\n",
    "        return x_reconst, mu, log_var\r\n",
    "\r\n",
    "model = VAE().to(device)\r\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Start training\r\n",
    "for epoch in range(num_epochs):\r\n",
    "    for i, (x, _) in enumerate(data_loader):\r\n",
    "        # Forward pass\r\n",
    "        x = x.to(device).view(-1, image_size)\r\n",
    "        x_reconst, mu, log_var = model(x)\r\n",
    "        \r\n",
    "        # Compute reconstruction loss and kl divergence\r\n",
    "        # For KL divergence, see Appendix B in VAE paper or http://yunjey47.tistory.com/43\r\n",
    "        reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\r\n",
    "        kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\r\n",
    "        \r\n",
    "        # Backprop and optimize\r\n",
    "        loss = reconst_loss + kl_div\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        \r\n",
    "        if (i+1) % 10 == 0:\r\n",
    "            print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}\" \r\n",
    "                   .format(epoch+1, num_epochs, i+1, len(data_loader), reconst_loss.item(), kl_div.item()))\r\n",
    "    \r\n",
    "    with torch.no_grad():\r\n",
    "        # Save the sampled images\r\n",
    "        z = torch.randn(batch_size, z_dim).to(device)\r\n",
    "        out = model.decode(z).view(-1, 1, 28, 28)\r\n",
    "        save_image(out, os.path.join(sample_dir, 'sampled-{}.png'.format(epoch+1)))\r\n",
    "\r\n",
    "        # Save the reconstructed images\r\n",
    "        out, _, _ = model(x)\r\n",
    "        x_concat = torch.cat([x.view(-1, 1, 28, 28), out.view(-1, 1, 28, 28)], dim=3)\r\n",
    "        save_image(x_concat, os.path.join(sample_dir, 'reconst-{}.png'.format(epoch+1)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "D:\\programs\\envs\\python38\\lib\\site-packages\\torch\\nn\\functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "D:\\programs\\envs\\python38\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch[1/15], Step [10/469], Reconst Loss: 35586.3164, KL Div: 3715.3994\n",
      "Epoch[1/15], Step [20/469], Reconst Loss: 29210.8906, KL Div: 1153.5503\n",
      "Epoch[1/15], Step [30/469], Reconst Loss: 27823.0098, KL Div: 1100.7793\n",
      "Epoch[1/15], Step [40/469], Reconst Loss: 26682.1055, KL Div: 710.4545\n",
      "Epoch[1/15], Step [50/469], Reconst Loss: 27193.1328, KL Div: 701.3678\n",
      "Epoch[1/15], Step [60/469], Reconst Loss: 26551.6367, KL Div: 791.0146\n",
      "Epoch[1/15], Step [70/469], Reconst Loss: 24572.6367, KL Div: 931.7997\n",
      "Epoch[1/15], Step [80/469], Reconst Loss: 23374.9531, KL Div: 1134.2720\n",
      "Epoch[1/15], Step [90/469], Reconst Loss: 22457.6719, KL Div: 1205.9314\n",
      "Epoch[1/15], Step [100/469], Reconst Loss: 21446.9062, KL Div: 1418.6650\n",
      "Epoch[1/15], Step [110/469], Reconst Loss: 21175.8320, KL Div: 1614.6514\n",
      "Epoch[1/15], Step [120/469], Reconst Loss: 20739.7930, KL Div: 1574.9617\n",
      "Epoch[1/15], Step [130/469], Reconst Loss: 19261.5000, KL Div: 1826.3440\n",
      "Epoch[1/15], Step [140/469], Reconst Loss: 19344.7168, KL Div: 1604.7300\n",
      "Epoch[1/15], Step [150/469], Reconst Loss: 19218.1777, KL Div: 1966.8142\n",
      "Epoch[1/15], Step [160/469], Reconst Loss: 18583.7422, KL Div: 1943.9399\n",
      "Epoch[1/15], Step [170/469], Reconst Loss: 18308.4492, KL Div: 1843.8101\n",
      "Epoch[1/15], Step [180/469], Reconst Loss: 17776.6367, KL Div: 1998.0284\n",
      "Epoch[1/15], Step [190/469], Reconst Loss: 17851.3262, KL Div: 1907.0327\n",
      "Epoch[1/15], Step [200/469], Reconst Loss: 17424.3066, KL Div: 1937.6733\n",
      "Epoch[1/15], Step [210/469], Reconst Loss: 17824.6816, KL Div: 2008.9998\n",
      "Epoch[1/15], Step [220/469], Reconst Loss: 17410.6055, KL Div: 2024.6138\n",
      "Epoch[1/15], Step [230/469], Reconst Loss: 17297.1875, KL Div: 2113.7139\n",
      "Epoch[1/15], Step [240/469], Reconst Loss: 16883.6719, KL Div: 2022.1348\n",
      "Epoch[1/15], Step [250/469], Reconst Loss: 17126.2109, KL Div: 2105.1943\n",
      "Epoch[1/15], Step [260/469], Reconst Loss: 16239.0420, KL Div: 2240.7061\n",
      "Epoch[1/15], Step [270/469], Reconst Loss: 15796.0176, KL Div: 2172.9634\n",
      "Epoch[1/15], Step [280/469], Reconst Loss: 16332.5234, KL Div: 2367.0425\n",
      "Epoch[1/15], Step [290/469], Reconst Loss: 15445.7480, KL Div: 2313.2412\n",
      "Epoch[1/15], Step [300/469], Reconst Loss: 15820.1309, KL Div: 2252.0156\n",
      "Epoch[1/15], Step [310/469], Reconst Loss: 15487.6689, KL Div: 2318.3906\n",
      "Epoch[1/15], Step [320/469], Reconst Loss: 15166.0654, KL Div: 2314.8743\n",
      "Epoch[1/15], Step [330/469], Reconst Loss: 14722.4453, KL Div: 2225.9717\n",
      "Epoch[1/15], Step [340/469], Reconst Loss: 15159.8926, KL Div: 2275.6746\n",
      "Epoch[1/15], Step [350/469], Reconst Loss: 15189.7783, KL Div: 2378.4048\n",
      "Epoch[1/15], Step [360/469], Reconst Loss: 14642.8242, KL Div: 2541.7249\n",
      "Epoch[1/15], Step [370/469], Reconst Loss: 15122.0488, KL Div: 2352.7021\n",
      "Epoch[1/15], Step [380/469], Reconst Loss: 14412.1572, KL Div: 2431.0393\n",
      "Epoch[1/15], Step [390/469], Reconst Loss: 14423.5898, KL Div: 2432.3193\n",
      "Epoch[1/15], Step [400/469], Reconst Loss: 14687.7676, KL Div: 2561.9458\n",
      "Epoch[1/15], Step [410/469], Reconst Loss: 14056.9717, KL Div: 2543.6145\n",
      "Epoch[1/15], Step [420/469], Reconst Loss: 14131.6260, KL Div: 2414.5813\n",
      "Epoch[1/15], Step [430/469], Reconst Loss: 14442.9512, KL Div: 2560.8760\n",
      "Epoch[1/15], Step [440/469], Reconst Loss: 13336.7197, KL Div: 2546.1953\n",
      "Epoch[1/15], Step [450/469], Reconst Loss: 13911.4902, KL Div: 2513.8643\n",
      "Epoch[1/15], Step [460/469], Reconst Loss: 14220.0527, KL Div: 2679.5552\n",
      "Epoch[2/15], Step [10/469], Reconst Loss: 13981.6152, KL Div: 2577.8945\n",
      "Epoch[2/15], Step [20/469], Reconst Loss: 13658.8770, KL Div: 2642.4404\n",
      "Epoch[2/15], Step [30/469], Reconst Loss: 13212.8770, KL Div: 2702.5757\n",
      "Epoch[2/15], Step [40/469], Reconst Loss: 13037.7725, KL Div: 2536.4360\n",
      "Epoch[2/15], Step [50/469], Reconst Loss: 14127.0957, KL Div: 2777.3906\n",
      "Epoch[2/15], Step [60/469], Reconst Loss: 13260.8027, KL Div: 2716.4585\n",
      "Epoch[2/15], Step [70/469], Reconst Loss: 12532.1260, KL Div: 2549.1960\n",
      "Epoch[2/15], Step [80/469], Reconst Loss: 13033.9277, KL Div: 2839.3496\n",
      "Epoch[2/15], Step [90/469], Reconst Loss: 13614.4600, KL Div: 2696.6211\n",
      "Epoch[2/15], Step [100/469], Reconst Loss: 13094.3506, KL Div: 2781.2720\n",
      "Epoch[2/15], Step [110/469], Reconst Loss: 13383.1230, KL Div: 2659.4355\n",
      "Epoch[2/15], Step [120/469], Reconst Loss: 13245.4844, KL Div: 2783.8535\n",
      "Epoch[2/15], Step [130/469], Reconst Loss: 13024.6367, KL Div: 2656.6294\n",
      "Epoch[2/15], Step [140/469], Reconst Loss: 13343.1387, KL Div: 2818.8711\n",
      "Epoch[2/15], Step [150/469], Reconst Loss: 13249.5859, KL Div: 2785.2397\n",
      "Epoch[2/15], Step [160/469], Reconst Loss: 13052.9111, KL Div: 2730.1060\n",
      "Epoch[2/15], Step [170/469], Reconst Loss: 12930.6631, KL Div: 2661.0881\n",
      "Epoch[2/15], Step [180/469], Reconst Loss: 13015.6328, KL Div: 2889.3018\n",
      "Epoch[2/15], Step [190/469], Reconst Loss: 12846.0195, KL Div: 2850.8306\n",
      "Epoch[2/15], Step [200/469], Reconst Loss: 12218.7363, KL Div: 2776.7988\n",
      "Epoch[2/15], Step [210/469], Reconst Loss: 13183.9238, KL Div: 2849.7905\n",
      "Epoch[2/15], Step [220/469], Reconst Loss: 12759.2793, KL Div: 2816.8689\n",
      "Epoch[2/15], Step [230/469], Reconst Loss: 12442.0312, KL Div: 2951.4966\n",
      "Epoch[2/15], Step [240/469], Reconst Loss: 12615.3535, KL Div: 2777.0708\n",
      "Epoch[2/15], Step [250/469], Reconst Loss: 12252.3262, KL Div: 2778.5063\n",
      "Epoch[2/15], Step [260/469], Reconst Loss: 12330.5137, KL Div: 2809.2126\n",
      "Epoch[2/15], Step [270/469], Reconst Loss: 12545.0537, KL Div: 2859.7947\n",
      "Epoch[2/15], Step [280/469], Reconst Loss: 12499.5215, KL Div: 2791.1179\n",
      "Epoch[2/15], Step [290/469], Reconst Loss: 12857.0010, KL Div: 2835.1914\n",
      "Epoch[2/15], Step [300/469], Reconst Loss: 12291.4443, KL Div: 2914.7910\n",
      "Epoch[2/15], Step [310/469], Reconst Loss: 12443.8066, KL Div: 2830.6958\n",
      "Epoch[2/15], Step [320/469], Reconst Loss: 12623.1621, KL Div: 2887.8364\n",
      "Epoch[2/15], Step [330/469], Reconst Loss: 12597.8213, KL Div: 2883.8857\n",
      "Epoch[2/15], Step [340/469], Reconst Loss: 11854.7676, KL Div: 2912.1997\n",
      "Epoch[2/15], Step [350/469], Reconst Loss: 12665.0586, KL Div: 2878.3970\n",
      "Epoch[2/15], Step [360/469], Reconst Loss: 12387.8516, KL Div: 2845.8901\n",
      "Epoch[2/15], Step [370/469], Reconst Loss: 12476.3770, KL Div: 2880.1538\n",
      "Epoch[2/15], Step [380/469], Reconst Loss: 12150.9824, KL Div: 2893.6431\n",
      "Epoch[2/15], Step [390/469], Reconst Loss: 12459.6445, KL Div: 3015.8193\n",
      "Epoch[2/15], Step [400/469], Reconst Loss: 12138.3594, KL Div: 2916.2246\n",
      "Epoch[2/15], Step [410/469], Reconst Loss: 12632.6348, KL Div: 2840.4263\n",
      "Epoch[2/15], Step [420/469], Reconst Loss: 12003.5342, KL Div: 3014.8564\n",
      "Epoch[2/15], Step [430/469], Reconst Loss: 12266.6660, KL Div: 2932.0991\n",
      "Epoch[2/15], Step [440/469], Reconst Loss: 12911.8115, KL Div: 2971.4658\n",
      "Epoch[2/15], Step [450/469], Reconst Loss: 11699.1631, KL Div: 2862.5640\n",
      "Epoch[2/15], Step [460/469], Reconst Loss: 12484.0986, KL Div: 3044.8513\n",
      "Epoch[3/15], Step [10/469], Reconst Loss: 11532.9580, KL Div: 3014.3909\n",
      "Epoch[3/15], Step [20/469], Reconst Loss: 11308.7236, KL Div: 2992.3044\n",
      "Epoch[3/15], Step [30/469], Reconst Loss: 11784.6660, KL Div: 2951.8926\n",
      "Epoch[3/15], Step [40/469], Reconst Loss: 12111.4629, KL Div: 3054.5891\n",
      "Epoch[3/15], Step [50/469], Reconst Loss: 11502.7998, KL Div: 2939.7141\n",
      "Epoch[3/15], Step [60/469], Reconst Loss: 11876.6182, KL Div: 3005.0981\n",
      "Epoch[3/15], Step [70/469], Reconst Loss: 12225.5332, KL Div: 3007.2637\n",
      "Epoch[3/15], Step [80/469], Reconst Loss: 12099.3555, KL Div: 2984.5945\n",
      "Epoch[3/15], Step [90/469], Reconst Loss: 11864.6865, KL Div: 2965.9312\n",
      "Epoch[3/15], Step [100/469], Reconst Loss: 11409.0508, KL Div: 2961.6016\n",
      "Epoch[3/15], Step [110/469], Reconst Loss: 12128.9648, KL Div: 2961.0996\n",
      "Epoch[3/15], Step [120/469], Reconst Loss: 11747.1777, KL Div: 3109.4124\n",
      "Epoch[3/15], Step [130/469], Reconst Loss: 11713.9922, KL Div: 2961.9297\n",
      "Epoch[3/15], Step [140/469], Reconst Loss: 11918.9316, KL Div: 2958.7695\n",
      "Epoch[3/15], Step [150/469], Reconst Loss: 11184.1289, KL Div: 3053.1631\n",
      "Epoch[3/15], Step [160/469], Reconst Loss: 11416.3604, KL Div: 2932.1001\n",
      "Epoch[3/15], Step [170/469], Reconst Loss: 11552.3662, KL Div: 2978.5815\n",
      "Epoch[3/15], Step [180/469], Reconst Loss: 11808.0859, KL Div: 2953.0649\n",
      "Epoch[3/15], Step [190/469], Reconst Loss: 11520.9717, KL Div: 3115.4275\n",
      "Epoch[3/15], Step [200/469], Reconst Loss: 11715.4102, KL Div: 3073.8120\n",
      "Epoch[3/15], Step [210/469], Reconst Loss: 11358.6777, KL Div: 2973.3713\n",
      "Epoch[3/15], Step [220/469], Reconst Loss: 11743.2666, KL Div: 3034.5103\n",
      "Epoch[3/15], Step [230/469], Reconst Loss: 11800.0898, KL Div: 3024.7976\n",
      "Epoch[3/15], Step [240/469], Reconst Loss: 11982.4365, KL Div: 3078.7734\n",
      "Epoch[3/15], Step [250/469], Reconst Loss: 11816.1699, KL Div: 2999.4546\n",
      "Epoch[3/15], Step [260/469], Reconst Loss: 11156.8633, KL Div: 3077.2915\n",
      "Epoch[3/15], Step [270/469], Reconst Loss: 11522.4492, KL Div: 3053.2898\n",
      "Epoch[3/15], Step [280/469], Reconst Loss: 11301.2451, KL Div: 3070.5918\n",
      "Epoch[3/15], Step [290/469], Reconst Loss: 11176.0615, KL Div: 3026.0691\n",
      "Epoch[3/15], Step [300/469], Reconst Loss: 11722.9883, KL Div: 3067.6157\n",
      "Epoch[3/15], Step [310/469], Reconst Loss: 11591.4766, KL Div: 3112.1824\n",
      "Epoch[3/15], Step [320/469], Reconst Loss: 11686.5723, KL Div: 3021.8735\n",
      "Epoch[3/15], Step [330/469], Reconst Loss: 11591.1387, KL Div: 3195.5083\n",
      "Epoch[3/15], Step [340/469], Reconst Loss: 11637.0850, KL Div: 3095.5151\n",
      "Epoch[3/15], Step [350/469], Reconst Loss: 11845.4092, KL Div: 3124.9854\n",
      "Epoch[3/15], Step [360/469], Reconst Loss: 11428.6660, KL Div: 2983.7988\n",
      "Epoch[3/15], Step [370/469], Reconst Loss: 11617.6758, KL Div: 3155.9312\n",
      "Epoch[3/15], Step [380/469], Reconst Loss: 11245.7012, KL Div: 3201.6204\n",
      "Epoch[3/15], Step [390/469], Reconst Loss: 11655.0684, KL Div: 2931.0613\n",
      "Epoch[3/15], Step [400/469], Reconst Loss: 11789.1191, KL Div: 3030.5264\n",
      "Epoch[3/15], Step [410/469], Reconst Loss: 11782.6650, KL Div: 3188.7344\n",
      "Epoch[3/15], Step [420/469], Reconst Loss: 11608.0010, KL Div: 3128.2263\n",
      "Epoch[3/15], Step [430/469], Reconst Loss: 11085.4023, KL Div: 3033.0684\n",
      "Epoch[3/15], Step [440/469], Reconst Loss: 11877.0947, KL Div: 3141.2300\n",
      "Epoch[3/15], Step [450/469], Reconst Loss: 10992.9805, KL Div: 3058.1987\n",
      "Epoch[3/15], Step [460/469], Reconst Loss: 11186.7607, KL Div: 2925.6570\n",
      "Epoch[4/15], Step [10/469], Reconst Loss: 11526.4678, KL Div: 2981.5840\n",
      "Epoch[4/15], Step [20/469], Reconst Loss: 10966.6396, KL Div: 3032.2500\n",
      "Epoch[4/15], Step [30/469], Reconst Loss: 11058.1816, KL Div: 3020.5217\n",
      "Epoch[4/15], Step [40/469], Reconst Loss: 10958.4180, KL Div: 3062.3608\n",
      "Epoch[4/15], Step [50/469], Reconst Loss: 11161.5186, KL Div: 3105.2937\n",
      "Epoch[4/15], Step [60/469], Reconst Loss: 11496.1152, KL Div: 3098.0574\n",
      "Epoch[4/15], Step [70/469], Reconst Loss: 12135.5801, KL Div: 3031.0791\n",
      "Epoch[4/15], Step [80/469], Reconst Loss: 11333.1758, KL Div: 3066.4626\n",
      "Epoch[4/15], Step [90/469], Reconst Loss: 10758.1992, KL Div: 3037.4146\n",
      "Epoch[4/15], Step [100/469], Reconst Loss: 11138.5625, KL Div: 3097.1929\n",
      "Epoch[4/15], Step [110/469], Reconst Loss: 11248.9014, KL Div: 3100.9656\n",
      "Epoch[4/15], Step [120/469], Reconst Loss: 11540.0859, KL Div: 3241.7776\n",
      "Epoch[4/15], Step [130/469], Reconst Loss: 11415.4756, KL Div: 3133.5134\n",
      "Epoch[4/15], Step [140/469], Reconst Loss: 11286.2744, KL Div: 3216.5332\n",
      "Epoch[4/15], Step [150/469], Reconst Loss: 11291.0762, KL Div: 3086.2471\n",
      "Epoch[4/15], Step [160/469], Reconst Loss: 11188.5879, KL Div: 3167.2783\n",
      "Epoch[4/15], Step [170/469], Reconst Loss: 11409.8516, KL Div: 3162.9355\n",
      "Epoch[4/15], Step [180/469], Reconst Loss: 11026.9229, KL Div: 3092.5200\n",
      "Epoch[4/15], Step [190/469], Reconst Loss: 11191.6367, KL Div: 3173.4866\n",
      "Epoch[4/15], Step [200/469], Reconst Loss: 11071.4463, KL Div: 3074.7773\n",
      "Epoch[4/15], Step [210/469], Reconst Loss: 11715.6826, KL Div: 3099.3386\n",
      "Epoch[4/15], Step [220/469], Reconst Loss: 11184.9111, KL Div: 3196.2864\n",
      "Epoch[4/15], Step [230/469], Reconst Loss: 10837.5371, KL Div: 3118.3730\n",
      "Epoch[4/15], Step [240/469], Reconst Loss: 10692.9971, KL Div: 3040.1667\n",
      "Epoch[4/15], Step [250/469], Reconst Loss: 10985.2227, KL Div: 3235.2688\n",
      "Epoch[4/15], Step [260/469], Reconst Loss: 11097.5166, KL Div: 3084.2854\n",
      "Epoch[4/15], Step [270/469], Reconst Loss: 11008.4727, KL Div: 3154.3203\n",
      "Epoch[4/15], Step [280/469], Reconst Loss: 11504.5410, KL Div: 3091.2969\n",
      "Epoch[4/15], Step [290/469], Reconst Loss: 10884.4170, KL Div: 3129.9570\n",
      "Epoch[4/15], Step [300/469], Reconst Loss: 11378.7422, KL Div: 3216.2957\n",
      "Epoch[4/15], Step [310/469], Reconst Loss: 10689.7793, KL Div: 2991.2666\n",
      "Epoch[4/15], Step [320/469], Reconst Loss: 11049.5938, KL Div: 3141.6230\n",
      "Epoch[4/15], Step [330/469], Reconst Loss: 10990.8105, KL Div: 3214.3979\n",
      "Epoch[4/15], Step [340/469], Reconst Loss: 10678.5664, KL Div: 3174.7449\n",
      "Epoch[4/15], Step [350/469], Reconst Loss: 11260.7383, KL Div: 3123.4148\n",
      "Epoch[4/15], Step [360/469], Reconst Loss: 10726.3613, KL Div: 3113.2776\n",
      "Epoch[4/15], Step [370/469], Reconst Loss: 10926.6309, KL Div: 3182.1628\n",
      "Epoch[4/15], Step [380/469], Reconst Loss: 11095.6484, KL Div: 3085.5732\n",
      "Epoch[4/15], Step [390/469], Reconst Loss: 11618.2715, KL Div: 3303.3469\n",
      "Epoch[4/15], Step [400/469], Reconst Loss: 11330.1914, KL Div: 3091.5220\n",
      "Epoch[4/15], Step [410/469], Reconst Loss: 10781.5254, KL Div: 3125.3518\n",
      "Epoch[4/15], Step [420/469], Reconst Loss: 10747.9170, KL Div: 3059.1436\n",
      "Epoch[4/15], Step [430/469], Reconst Loss: 10815.2373, KL Div: 3133.7061\n",
      "Epoch[4/15], Step [440/469], Reconst Loss: 11079.3086, KL Div: 3206.6221\n",
      "Epoch[4/15], Step [450/469], Reconst Loss: 11436.1094, KL Div: 3100.4326\n",
      "Epoch[4/15], Step [460/469], Reconst Loss: 10548.8242, KL Div: 3126.3672\n",
      "Epoch[5/15], Step [10/469], Reconst Loss: 11078.3262, KL Div: 3196.8423\n",
      "Epoch[5/15], Step [20/469], Reconst Loss: 10665.3242, KL Div: 3168.5005\n",
      "Epoch[5/15], Step [30/469], Reconst Loss: 10471.5342, KL Div: 3043.4253\n",
      "Epoch[5/15], Step [40/469], Reconst Loss: 10920.0518, KL Div: 3206.7131\n",
      "Epoch[5/15], Step [50/469], Reconst Loss: 10679.6680, KL Div: 3125.8572\n",
      "Epoch[5/15], Step [60/469], Reconst Loss: 10726.3105, KL Div: 3186.5879\n",
      "Epoch[5/15], Step [70/469], Reconst Loss: 11041.1914, KL Div: 3082.2141\n",
      "Epoch[5/15], Step [80/469], Reconst Loss: 11214.3525, KL Div: 3253.8306\n",
      "Epoch[5/15], Step [90/469], Reconst Loss: 11197.9209, KL Div: 3223.9763\n",
      "Epoch[5/15], Step [100/469], Reconst Loss: 11137.8633, KL Div: 3163.0593\n",
      "Epoch[5/15], Step [110/469], Reconst Loss: 11252.0801, KL Div: 3156.3833\n",
      "Epoch[5/15], Step [120/469], Reconst Loss: 10609.3057, KL Div: 3231.3115\n",
      "Epoch[5/15], Step [130/469], Reconst Loss: 11531.0645, KL Div: 3134.8213\n",
      "Epoch[5/15], Step [140/469], Reconst Loss: 10556.9766, KL Div: 3100.7349\n",
      "Epoch[5/15], Step [150/469], Reconst Loss: 10579.7461, KL Div: 3050.6763\n",
      "Epoch[5/15], Step [160/469], Reconst Loss: 10934.7969, KL Div: 3258.4851\n",
      "Epoch[5/15], Step [170/469], Reconst Loss: 10667.2334, KL Div: 3028.2214\n",
      "Epoch[5/15], Step [180/469], Reconst Loss: 11001.0020, KL Div: 3181.8855\n",
      "Epoch[5/15], Step [190/469], Reconst Loss: 10852.3525, KL Div: 3179.7598\n",
      "Epoch[5/15], Step [200/469], Reconst Loss: 11080.3809, KL Div: 3204.2136\n",
      "Epoch[5/15], Step [210/469], Reconst Loss: 10940.5430, KL Div: 3227.4702\n",
      "Epoch[5/15], Step [220/469], Reconst Loss: 11637.6719, KL Div: 3240.0222\n",
      "Epoch[5/15], Step [230/469], Reconst Loss: 11004.1602, KL Div: 3165.7271\n",
      "Epoch[5/15], Step [240/469], Reconst Loss: 10907.1641, KL Div: 3199.7183\n",
      "Epoch[5/15], Step [250/469], Reconst Loss: 10588.3223, KL Div: 3215.8848\n",
      "Epoch[5/15], Step [260/469], Reconst Loss: 10406.4092, KL Div: 3125.5996\n",
      "Epoch[5/15], Step [270/469], Reconst Loss: 10016.5547, KL Div: 3184.8164\n",
      "Epoch[5/15], Step [280/469], Reconst Loss: 10629.9707, KL Div: 3226.2974\n",
      "Epoch[5/15], Step [290/469], Reconst Loss: 10580.0469, KL Div: 3052.5640\n",
      "Epoch[5/15], Step [300/469], Reconst Loss: 11032.0303, KL Div: 3223.8196\n",
      "Epoch[5/15], Step [310/469], Reconst Loss: 10769.2451, KL Div: 3093.2471\n",
      "Epoch[5/15], Step [320/469], Reconst Loss: 11037.9131, KL Div: 3160.0764\n",
      "Epoch[5/15], Step [330/469], Reconst Loss: 10309.9717, KL Div: 3066.3613\n",
      "Epoch[5/15], Step [340/469], Reconst Loss: 11016.4668, KL Div: 3194.0005\n",
      "Epoch[5/15], Step [350/469], Reconst Loss: 10891.5449, KL Div: 3198.2529\n",
      "Epoch[5/15], Step [360/469], Reconst Loss: 11124.0029, KL Div: 3173.7651\n",
      "Epoch[5/15], Step [370/469], Reconst Loss: 10545.7754, KL Div: 3167.3442\n",
      "Epoch[5/15], Step [380/469], Reconst Loss: 10671.4385, KL Div: 3197.5630\n",
      "Epoch[5/15], Step [390/469], Reconst Loss: 10950.0420, KL Div: 3114.7827\n",
      "Epoch[5/15], Step [400/469], Reconst Loss: 10868.9258, KL Div: 3289.4526\n",
      "Epoch[5/15], Step [410/469], Reconst Loss: 10592.0498, KL Div: 3219.5100\n",
      "Epoch[5/15], Step [420/469], Reconst Loss: 10093.6855, KL Div: 3207.6074\n",
      "Epoch[5/15], Step [430/469], Reconst Loss: 10516.9004, KL Div: 3142.6069\n",
      "Epoch[5/15], Step [440/469], Reconst Loss: 10762.4990, KL Div: 3134.1819\n",
      "Epoch[5/15], Step [450/469], Reconst Loss: 11083.4189, KL Div: 3159.1902\n",
      "Epoch[5/15], Step [460/469], Reconst Loss: 11427.6338, KL Div: 3238.6909\n",
      "Epoch[6/15], Step [10/469], Reconst Loss: 10872.1250, KL Div: 3217.2522\n",
      "Epoch[6/15], Step [20/469], Reconst Loss: 10521.9297, KL Div: 3171.4170\n",
      "Epoch[6/15], Step [30/469], Reconst Loss: 10382.8398, KL Div: 3219.3352\n",
      "Epoch[6/15], Step [40/469], Reconst Loss: 11126.0479, KL Div: 3110.1648\n",
      "Epoch[6/15], Step [50/469], Reconst Loss: 10611.4434, KL Div: 3207.1514\n",
      "Epoch[6/15], Step [60/469], Reconst Loss: 10588.4648, KL Div: 3204.2666\n",
      "Epoch[6/15], Step [70/469], Reconst Loss: 10968.3457, KL Div: 3201.4050\n",
      "Epoch[6/15], Step [80/469], Reconst Loss: 10958.0469, KL Div: 3293.5776\n",
      "Epoch[6/15], Step [90/469], Reconst Loss: 10624.9980, KL Div: 3235.6074\n",
      "Epoch[6/15], Step [100/469], Reconst Loss: 10786.9990, KL Div: 3228.8279\n",
      "Epoch[6/15], Step [110/469], Reconst Loss: 10621.0049, KL Div: 3207.8706\n",
      "Epoch[6/15], Step [120/469], Reconst Loss: 10517.5234, KL Div: 3234.5630\n",
      "Epoch[6/15], Step [130/469], Reconst Loss: 11059.7441, KL Div: 3111.7134\n",
      "Epoch[6/15], Step [140/469], Reconst Loss: 10841.9473, KL Div: 3203.3215\n",
      "Epoch[6/15], Step [150/469], Reconst Loss: 11103.3906, KL Div: 3116.7515\n",
      "Epoch[6/15], Step [160/469], Reconst Loss: 10590.2500, KL Div: 3256.5095\n",
      "Epoch[6/15], Step [170/469], Reconst Loss: 10549.7031, KL Div: 3184.4619\n",
      "Epoch[6/15], Step [180/469], Reconst Loss: 10493.3398, KL Div: 3255.8789\n",
      "Epoch[6/15], Step [190/469], Reconst Loss: 11138.8730, KL Div: 3159.4243\n",
      "Epoch[6/15], Step [200/469], Reconst Loss: 10518.3525, KL Div: 3229.3535\n",
      "Epoch[6/15], Step [210/469], Reconst Loss: 10578.9414, KL Div: 3154.7710\n",
      "Epoch[6/15], Step [220/469], Reconst Loss: 10664.1465, KL Div: 3102.6868\n",
      "Epoch[6/15], Step [230/469], Reconst Loss: 10768.3301, KL Div: 3228.9194\n",
      "Epoch[6/15], Step [240/469], Reconst Loss: 10991.7598, KL Div: 3222.9858\n",
      "Epoch[6/15], Step [250/469], Reconst Loss: 11062.0254, KL Div: 3226.5522\n",
      "Epoch[6/15], Step [260/469], Reconst Loss: 10542.2666, KL Div: 3215.8496\n",
      "Epoch[6/15], Step [270/469], Reconst Loss: 10545.7578, KL Div: 3112.5408\n",
      "Epoch[6/15], Step [280/469], Reconst Loss: 10580.7090, KL Div: 3300.3875\n",
      "Epoch[6/15], Step [290/469], Reconst Loss: 10803.0898, KL Div: 3123.0498\n",
      "Epoch[6/15], Step [300/469], Reconst Loss: 10560.2031, KL Div: 3188.8303\n",
      "Epoch[6/15], Step [310/469], Reconst Loss: 10232.2539, KL Div: 3123.1128\n",
      "Epoch[6/15], Step [320/469], Reconst Loss: 10941.9443, KL Div: 3227.8208\n",
      "Epoch[6/15], Step [330/469], Reconst Loss: 10281.5176, KL Div: 3215.3098\n",
      "Epoch[6/15], Step [340/469], Reconst Loss: 10782.0801, KL Div: 3149.9546\n",
      "Epoch[6/15], Step [350/469], Reconst Loss: 10770.6904, KL Div: 3255.6062\n",
      "Epoch[6/15], Step [360/469], Reconst Loss: 10338.4639, KL Div: 3075.1362\n",
      "Epoch[6/15], Step [370/469], Reconst Loss: 10661.5908, KL Div: 3272.1606\n",
      "Epoch[6/15], Step [380/469], Reconst Loss: 10694.4014, KL Div: 3174.7639\n",
      "Epoch[6/15], Step [390/469], Reconst Loss: 10041.0547, KL Div: 3041.4197\n",
      "Epoch[6/15], Step [400/469], Reconst Loss: 10805.9639, KL Div: 3304.2471\n",
      "Epoch[6/15], Step [410/469], Reconst Loss: 10290.6094, KL Div: 3164.7476\n",
      "Epoch[6/15], Step [420/469], Reconst Loss: 10458.2695, KL Div: 3244.6509\n",
      "Epoch[6/15], Step [430/469], Reconst Loss: 11040.6787, KL Div: 3268.3232\n",
      "Epoch[6/15], Step [440/469], Reconst Loss: 10930.1289, KL Div: 3198.3188\n",
      "Epoch[6/15], Step [450/469], Reconst Loss: 10543.1338, KL Div: 3239.1641\n",
      "Epoch[6/15], Step [460/469], Reconst Loss: 10486.2715, KL Div: 3123.8357\n",
      "Epoch[7/15], Step [10/469], Reconst Loss: 10578.7363, KL Div: 3216.3496\n",
      "Epoch[7/15], Step [20/469], Reconst Loss: 10605.0762, KL Div: 3186.7397\n",
      "Epoch[7/15], Step [30/469], Reconst Loss: 11180.5879, KL Div: 3195.5640\n",
      "Epoch[7/15], Step [40/469], Reconst Loss: 10695.5107, KL Div: 3169.2874\n",
      "Epoch[7/15], Step [50/469], Reconst Loss: 10157.6162, KL Div: 3170.9380\n",
      "Epoch[7/15], Step [60/469], Reconst Loss: 10509.2822, KL Div: 3134.4753\n",
      "Epoch[7/15], Step [70/469], Reconst Loss: 10468.5723, KL Div: 3198.4041\n",
      "Epoch[7/15], Step [80/469], Reconst Loss: 10490.0850, KL Div: 3252.3567\n",
      "Epoch[7/15], Step [90/469], Reconst Loss: 10553.4229, KL Div: 3087.9143\n",
      "Epoch[7/15], Step [100/469], Reconst Loss: 10062.0508, KL Div: 3190.3770\n",
      "Epoch[7/15], Step [110/469], Reconst Loss: 11004.6016, KL Div: 3113.9980\n",
      "Epoch[7/15], Step [120/469], Reconst Loss: 10679.9541, KL Div: 3270.3076\n",
      "Epoch[7/15], Step [130/469], Reconst Loss: 10422.2832, KL Div: 3136.0752\n",
      "Epoch[7/15], Step [140/469], Reconst Loss: 10754.1816, KL Div: 3157.2913\n",
      "Epoch[7/15], Step [150/469], Reconst Loss: 10822.0664, KL Div: 3278.5581\n",
      "Epoch[7/15], Step [160/469], Reconst Loss: 10460.0107, KL Div: 3101.0725\n",
      "Epoch[7/15], Step [170/469], Reconst Loss: 10532.1504, KL Div: 3179.4062\n",
      "Epoch[7/15], Step [180/469], Reconst Loss: 11123.0332, KL Div: 3280.7690\n",
      "Epoch[7/15], Step [190/469], Reconst Loss: 10477.8721, KL Div: 3208.3135\n",
      "Epoch[7/15], Step [200/469], Reconst Loss: 10406.8740, KL Div: 3189.6162\n",
      "Epoch[7/15], Step [210/469], Reconst Loss: 10563.6182, KL Div: 3174.8074\n",
      "Epoch[7/15], Step [220/469], Reconst Loss: 10302.2588, KL Div: 3195.0044\n",
      "Epoch[7/15], Step [230/469], Reconst Loss: 10373.7266, KL Div: 3271.1516\n",
      "Epoch[7/15], Step [240/469], Reconst Loss: 10491.0000, KL Div: 3107.0337\n",
      "Epoch[7/15], Step [250/469], Reconst Loss: 10513.9209, KL Div: 3322.2251\n",
      "Epoch[7/15], Step [260/469], Reconst Loss: 11342.2422, KL Div: 3200.7307\n",
      "Epoch[7/15], Step [270/469], Reconst Loss: 10744.5547, KL Div: 3260.6562\n",
      "Epoch[7/15], Step [280/469], Reconst Loss: 10170.4980, KL Div: 3188.5205\n",
      "Epoch[7/15], Step [290/469], Reconst Loss: 10489.6016, KL Div: 3118.5200\n",
      "Epoch[7/15], Step [300/469], Reconst Loss: 10992.1875, KL Div: 3188.3940\n",
      "Epoch[7/15], Step [310/469], Reconst Loss: 9930.7930, KL Div: 3284.9446\n",
      "Epoch[7/15], Step [320/469], Reconst Loss: 10818.5674, KL Div: 3093.8752\n",
      "Epoch[7/15], Step [330/469], Reconst Loss: 10981.5986, KL Div: 3258.1343\n",
      "Epoch[7/15], Step [340/469], Reconst Loss: 10062.5020, KL Div: 3091.5212\n",
      "Epoch[7/15], Step [350/469], Reconst Loss: 10453.8125, KL Div: 3224.4414\n",
      "Epoch[7/15], Step [360/469], Reconst Loss: 10651.8115, KL Div: 3080.8872\n",
      "Epoch[7/15], Step [370/469], Reconst Loss: 10135.5674, KL Div: 3228.4463\n",
      "Epoch[7/15], Step [380/469], Reconst Loss: 10226.0752, KL Div: 3085.3716\n",
      "Epoch[7/15], Step [390/469], Reconst Loss: 10652.9297, KL Div: 3367.8691\n",
      "Epoch[7/15], Step [400/469], Reconst Loss: 10392.4824, KL Div: 3141.9648\n",
      "Epoch[7/15], Step [410/469], Reconst Loss: 10561.5488, KL Div: 3168.8184\n",
      "Epoch[7/15], Step [420/469], Reconst Loss: 10361.6934, KL Div: 3267.1716\n",
      "Epoch[7/15], Step [430/469], Reconst Loss: 10600.9648, KL Div: 3177.5767\n",
      "Epoch[7/15], Step [440/469], Reconst Loss: 10124.0840, KL Div: 3137.2827\n",
      "Epoch[7/15], Step [450/469], Reconst Loss: 10683.1035, KL Div: 3345.9995\n",
      "Epoch[7/15], Step [460/469], Reconst Loss: 10102.7568, KL Div: 3107.8130\n",
      "Epoch[8/15], Step [10/469], Reconst Loss: 10291.7900, KL Div: 3217.0508\n",
      "Epoch[8/15], Step [20/469], Reconst Loss: 10443.6035, KL Div: 3087.3088\n",
      "Epoch[8/15], Step [30/469], Reconst Loss: 10263.0488, KL Div: 3241.5088\n",
      "Epoch[8/15], Step [40/469], Reconst Loss: 10407.3525, KL Div: 3198.5977\n",
      "Epoch[8/15], Step [50/469], Reconst Loss: 10433.7676, KL Div: 3183.6287\n",
      "Epoch[8/15], Step [60/469], Reconst Loss: 10364.6387, KL Div: 3274.2056\n",
      "Epoch[8/15], Step [70/469], Reconst Loss: 10649.9902, KL Div: 3214.6816\n",
      "Epoch[8/15], Step [80/469], Reconst Loss: 10353.4492, KL Div: 3209.1855\n",
      "Epoch[8/15], Step [90/469], Reconst Loss: 10509.0312, KL Div: 3176.0605\n",
      "Epoch[8/15], Step [100/469], Reconst Loss: 10715.1250, KL Div: 3121.3186\n",
      "Epoch[8/15], Step [110/469], Reconst Loss: 10497.2363, KL Div: 3251.7107\n",
      "Epoch[8/15], Step [120/469], Reconst Loss: 10604.8340, KL Div: 3205.7002\n",
      "Epoch[8/15], Step [130/469], Reconst Loss: 10305.2324, KL Div: 3203.8428\n",
      "Epoch[8/15], Step [140/469], Reconst Loss: 10274.9824, KL Div: 3133.9863\n",
      "Epoch[8/15], Step [150/469], Reconst Loss: 10798.4102, KL Div: 3133.0239\n",
      "Epoch[8/15], Step [160/469], Reconst Loss: 10711.2646, KL Div: 3256.5361\n",
      "Epoch[8/15], Step [170/469], Reconst Loss: 10729.9834, KL Div: 3203.4736\n",
      "Epoch[8/15], Step [180/469], Reconst Loss: 10851.9004, KL Div: 3178.7144\n",
      "Epoch[8/15], Step [190/469], Reconst Loss: 9988.0703, KL Div: 3192.4614\n",
      "Epoch[8/15], Step [200/469], Reconst Loss: 10088.3965, KL Div: 3170.0317\n",
      "Epoch[8/15], Step [210/469], Reconst Loss: 10651.3672, KL Div: 3283.7788\n",
      "Epoch[8/15], Step [220/469], Reconst Loss: 10863.7988, KL Div: 3154.1636\n",
      "Epoch[8/15], Step [230/469], Reconst Loss: 10555.0039, KL Div: 3342.5735\n",
      "Epoch[8/15], Step [240/469], Reconst Loss: 10273.5312, KL Div: 3186.5898\n",
      "Epoch[8/15], Step [250/469], Reconst Loss: 10132.6094, KL Div: 3192.9175\n",
      "Epoch[8/15], Step [260/469], Reconst Loss: 10582.1602, KL Div: 3236.3979\n",
      "Epoch[8/15], Step [270/469], Reconst Loss: 10425.4004, KL Div: 3258.9612\n",
      "Epoch[8/15], Step [280/469], Reconst Loss: 10825.9678, KL Div: 3218.7090\n",
      "Epoch[8/15], Step [290/469], Reconst Loss: 10869.5000, KL Div: 3309.7627\n",
      "Epoch[8/15], Step [300/469], Reconst Loss: 10448.6650, KL Div: 3287.2327\n",
      "Epoch[8/15], Step [310/469], Reconst Loss: 10290.7090, KL Div: 3086.1865\n",
      "Epoch[8/15], Step [320/469], Reconst Loss: 10399.0000, KL Div: 3183.8049\n",
      "Epoch[8/15], Step [330/469], Reconst Loss: 10473.1104, KL Div: 3205.5579\n",
      "Epoch[8/15], Step [340/469], Reconst Loss: 10323.0957, KL Div: 3242.1777\n",
      "Epoch[8/15], Step [350/469], Reconst Loss: 10583.0898, KL Div: 3241.4429\n",
      "Epoch[8/15], Step [360/469], Reconst Loss: 10809.5361, KL Div: 3245.5630\n",
      "Epoch[8/15], Step [370/469], Reconst Loss: 10373.7666, KL Div: 3239.6777\n",
      "Epoch[8/15], Step [380/469], Reconst Loss: 10840.1992, KL Div: 3255.3638\n",
      "Epoch[8/15], Step [390/469], Reconst Loss: 10338.4736, KL Div: 3196.6987\n",
      "Epoch[8/15], Step [400/469], Reconst Loss: 10167.4658, KL Div: 3194.5962\n",
      "Epoch[8/15], Step [410/469], Reconst Loss: 10647.0547, KL Div: 3224.7314\n",
      "Epoch[8/15], Step [420/469], Reconst Loss: 10561.4346, KL Div: 3219.9167\n",
      "Epoch[8/15], Step [430/469], Reconst Loss: 10558.4971, KL Div: 3329.2812\n",
      "Epoch[8/15], Step [440/469], Reconst Loss: 10452.6631, KL Div: 3221.9941\n",
      "Epoch[8/15], Step [450/469], Reconst Loss: 10660.0703, KL Div: 3245.2327\n",
      "Epoch[8/15], Step [460/469], Reconst Loss: 10589.5928, KL Div: 3324.2336\n",
      "Epoch[9/15], Step [10/469], Reconst Loss: 10194.0566, KL Div: 3205.4814\n",
      "Epoch[9/15], Step [20/469], Reconst Loss: 10611.5850, KL Div: 3260.0688\n",
      "Epoch[9/15], Step [30/469], Reconst Loss: 10550.3652, KL Div: 3381.3235\n",
      "Epoch[9/15], Step [40/469], Reconst Loss: 10347.3369, KL Div: 3084.6418\n",
      "Epoch[9/15], Step [50/469], Reconst Loss: 10682.2676, KL Div: 3309.4141\n",
      "Epoch[9/15], Step [60/469], Reconst Loss: 10636.8047, KL Div: 3303.7954\n",
      "Epoch[9/15], Step [70/469], Reconst Loss: 10447.6328, KL Div: 3214.6235\n",
      "Epoch[9/15], Step [80/469], Reconst Loss: 10728.5742, KL Div: 3163.3550\n",
      "Epoch[9/15], Step [90/469], Reconst Loss: 10317.1689, KL Div: 3273.8572\n",
      "Epoch[9/15], Step [100/469], Reconst Loss: 10321.3613, KL Div: 3143.9038\n",
      "Epoch[9/15], Step [110/469], Reconst Loss: 10142.7754, KL Div: 3157.0757\n",
      "Epoch[9/15], Step [120/469], Reconst Loss: 10420.3965, KL Div: 3204.7803\n",
      "Epoch[9/15], Step [130/469], Reconst Loss: 10952.4531, KL Div: 3267.6851\n",
      "Epoch[9/15], Step [140/469], Reconst Loss: 10184.0254, KL Div: 3260.8230\n",
      "Epoch[9/15], Step [150/469], Reconst Loss: 10769.2539, KL Div: 3250.7173\n",
      "Epoch[9/15], Step [160/469], Reconst Loss: 10457.1768, KL Div: 3201.1675\n",
      "Epoch[9/15], Step [170/469], Reconst Loss: 10250.6738, KL Div: 3121.2468\n",
      "Epoch[9/15], Step [180/469], Reconst Loss: 10133.9551, KL Div: 3247.4189\n",
      "Epoch[9/15], Step [190/469], Reconst Loss: 10538.2070, KL Div: 3290.1589\n",
      "Epoch[9/15], Step [200/469], Reconst Loss: 10116.4746, KL Div: 3124.2593\n",
      "Epoch[9/15], Step [210/469], Reconst Loss: 10671.0840, KL Div: 3165.6421\n",
      "Epoch[9/15], Step [220/469], Reconst Loss: 10140.6357, KL Div: 3209.5635\n",
      "Epoch[9/15], Step [230/469], Reconst Loss: 10218.3936, KL Div: 3124.8179\n",
      "Epoch[9/15], Step [240/469], Reconst Loss: 10612.9014, KL Div: 3302.9043\n",
      "Epoch[9/15], Step [250/469], Reconst Loss: 10340.9932, KL Div: 3187.8948\n",
      "Epoch[9/15], Step [260/469], Reconst Loss: 10628.9326, KL Div: 3322.4653\n",
      "Epoch[9/15], Step [270/469], Reconst Loss: 9763.1025, KL Div: 3154.8618\n",
      "Epoch[9/15], Step [280/469], Reconst Loss: 10505.9883, KL Div: 3190.2202\n",
      "Epoch[9/15], Step [290/469], Reconst Loss: 10543.4678, KL Div: 3112.6025\n",
      "Epoch[9/15], Step [300/469], Reconst Loss: 10361.8613, KL Div: 3229.5364\n",
      "Epoch[9/15], Step [310/469], Reconst Loss: 10359.0430, KL Div: 3165.5146\n",
      "Epoch[9/15], Step [320/469], Reconst Loss: 10366.8438, KL Div: 3254.8518\n",
      "Epoch[9/15], Step [330/469], Reconst Loss: 10385.3809, KL Div: 3230.3135\n",
      "Epoch[9/15], Step [340/469], Reconst Loss: 10279.1992, KL Div: 3277.9692\n",
      "Epoch[9/15], Step [350/469], Reconst Loss: 10317.1309, KL Div: 3211.5366\n",
      "Epoch[9/15], Step [360/469], Reconst Loss: 10563.8359, KL Div: 3213.3237\n",
      "Epoch[9/15], Step [370/469], Reconst Loss: 10478.6816, KL Div: 3166.1489\n",
      "Epoch[9/15], Step [380/469], Reconst Loss: 10364.0156, KL Div: 3225.9885\n",
      "Epoch[9/15], Step [390/469], Reconst Loss: 10541.8281, KL Div: 3270.8281\n",
      "Epoch[9/15], Step [400/469], Reconst Loss: 10569.7451, KL Div: 3263.0100\n",
      "Epoch[9/15], Step [410/469], Reconst Loss: 10421.9287, KL Div: 3215.7095\n",
      "Epoch[9/15], Step [420/469], Reconst Loss: 10726.0469, KL Div: 3223.5603\n",
      "Epoch[9/15], Step [430/469], Reconst Loss: 10270.5215, KL Div: 3296.5203\n",
      "Epoch[9/15], Step [440/469], Reconst Loss: 10232.1035, KL Div: 3142.4336\n",
      "Epoch[9/15], Step [450/469], Reconst Loss: 10741.6553, KL Div: 3207.6277\n",
      "Epoch[9/15], Step [460/469], Reconst Loss: 10078.2305, KL Div: 3152.3389\n",
      "Epoch[10/15], Step [10/469], Reconst Loss: 10214.7617, KL Div: 3159.2917\n",
      "Epoch[10/15], Step [20/469], Reconst Loss: 10511.0938, KL Div: 3213.2363\n",
      "Epoch[10/15], Step [30/469], Reconst Loss: 10000.7012, KL Div: 3259.1260\n",
      "Epoch[10/15], Step [40/469], Reconst Loss: 10819.7461, KL Div: 3293.7324\n",
      "Epoch[10/15], Step [50/469], Reconst Loss: 10293.8184, KL Div: 3191.4199\n",
      "Epoch[10/15], Step [60/469], Reconst Loss: 10248.1934, KL Div: 3156.7720\n",
      "Epoch[10/15], Step [70/469], Reconst Loss: 10435.3867, KL Div: 3105.6040\n",
      "Epoch[10/15], Step [80/469], Reconst Loss: 10119.5947, KL Div: 3332.2065\n",
      "Epoch[10/15], Step [90/469], Reconst Loss: 11032.5918, KL Div: 3230.5566\n",
      "Epoch[10/15], Step [100/469], Reconst Loss: 10536.1768, KL Div: 3282.8821\n",
      "Epoch[10/15], Step [110/469], Reconst Loss: 10081.6631, KL Div: 3186.8567\n",
      "Epoch[10/15], Step [120/469], Reconst Loss: 10361.4033, KL Div: 3275.6543\n",
      "Epoch[10/15], Step [130/469], Reconst Loss: 10523.6797, KL Div: 3298.3706\n",
      "Epoch[10/15], Step [140/469], Reconst Loss: 9742.0508, KL Div: 3054.2021\n",
      "Epoch[10/15], Step [150/469], Reconst Loss: 10045.8311, KL Div: 3197.8247\n",
      "Epoch[10/15], Step [160/469], Reconst Loss: 10356.3418, KL Div: 3243.2222\n",
      "Epoch[10/15], Step [170/469], Reconst Loss: 10540.0879, KL Div: 3171.4866\n",
      "Epoch[10/15], Step [180/469], Reconst Loss: 10448.2188, KL Div: 3151.1440\n",
      "Epoch[10/15], Step [190/469], Reconst Loss: 10748.0576, KL Div: 3324.2764\n",
      "Epoch[10/15], Step [200/469], Reconst Loss: 10109.5957, KL Div: 3191.4595\n",
      "Epoch[10/15], Step [210/469], Reconst Loss: 10330.4014, KL Div: 3222.9771\n",
      "Epoch[10/15], Step [220/469], Reconst Loss: 10750.3955, KL Div: 3278.9312\n",
      "Epoch[10/15], Step [230/469], Reconst Loss: 10721.1758, KL Div: 3266.2903\n",
      "Epoch[10/15], Step [240/469], Reconst Loss: 10380.4824, KL Div: 3172.8857\n",
      "Epoch[10/15], Step [250/469], Reconst Loss: 10012.1318, KL Div: 3178.8472\n",
      "Epoch[10/15], Step [260/469], Reconst Loss: 10278.2500, KL Div: 3219.1719\n",
      "Epoch[10/15], Step [270/469], Reconst Loss: 10454.5420, KL Div: 3202.9792\n",
      "Epoch[10/15], Step [280/469], Reconst Loss: 10302.4414, KL Div: 3260.9421\n",
      "Epoch[10/15], Step [290/469], Reconst Loss: 10143.4609, KL Div: 3121.5425\n",
      "Epoch[10/15], Step [300/469], Reconst Loss: 10240.1865, KL Div: 3215.8013\n",
      "Epoch[10/15], Step [310/469], Reconst Loss: 9971.1562, KL Div: 3164.2522\n",
      "Epoch[10/15], Step [320/469], Reconst Loss: 10363.5176, KL Div: 3159.2886\n",
      "Epoch[10/15], Step [330/469], Reconst Loss: 10107.2393, KL Div: 3154.8467\n",
      "Epoch[10/15], Step [340/469], Reconst Loss: 10299.9746, KL Div: 3035.4097\n",
      "Epoch[10/15], Step [350/469], Reconst Loss: 10261.3711, KL Div: 3246.5735\n",
      "Epoch[10/15], Step [360/469], Reconst Loss: 10605.5566, KL Div: 3196.1245\n",
      "Epoch[10/15], Step [370/469], Reconst Loss: 10200.8086, KL Div: 3192.8657\n",
      "Epoch[10/15], Step [380/469], Reconst Loss: 10160.2949, KL Div: 3263.7422\n",
      "Epoch[10/15], Step [390/469], Reconst Loss: 10760.4355, KL Div: 3300.5522\n",
      "Epoch[10/15], Step [400/469], Reconst Loss: 10160.0137, KL Div: 3232.8115\n",
      "Epoch[10/15], Step [410/469], Reconst Loss: 10276.0029, KL Div: 3317.1318\n",
      "Epoch[10/15], Step [420/469], Reconst Loss: 10559.6592, KL Div: 3172.4902\n",
      "Epoch[10/15], Step [430/469], Reconst Loss: 10680.0547, KL Div: 3169.7197\n",
      "Epoch[10/15], Step [440/469], Reconst Loss: 10509.8379, KL Div: 3215.9932\n",
      "Epoch[10/15], Step [450/469], Reconst Loss: 10323.0547, KL Div: 3245.1909\n",
      "Epoch[10/15], Step [460/469], Reconst Loss: 10102.9951, KL Div: 3175.7383\n",
      "Epoch[11/15], Step [10/469], Reconst Loss: 10646.2285, KL Div: 3257.0596\n",
      "Epoch[11/15], Step [20/469], Reconst Loss: 10189.9365, KL Div: 3183.8467\n",
      "Epoch[11/15], Step [30/469], Reconst Loss: 10641.6094, KL Div: 3255.9092\n",
      "Epoch[11/15], Step [40/469], Reconst Loss: 10559.5518, KL Div: 3178.8591\n",
      "Epoch[11/15], Step [50/469], Reconst Loss: 10344.6787, KL Div: 3300.0479\n",
      "Epoch[11/15], Step [60/469], Reconst Loss: 10356.0449, KL Div: 3086.2849\n",
      "Epoch[11/15], Step [70/469], Reconst Loss: 10248.8906, KL Div: 3263.5908\n",
      "Epoch[11/15], Step [80/469], Reconst Loss: 10249.3828, KL Div: 3308.6394\n",
      "Epoch[11/15], Step [90/469], Reconst Loss: 10623.2363, KL Div: 3186.4143\n",
      "Epoch[11/15], Step [100/469], Reconst Loss: 10019.4453, KL Div: 3189.3955\n",
      "Epoch[11/15], Step [110/469], Reconst Loss: 10343.5078, KL Div: 3258.7314\n",
      "Epoch[11/15], Step [120/469], Reconst Loss: 10202.6973, KL Div: 3237.6797\n",
      "Epoch[11/15], Step [130/469], Reconst Loss: 10255.4717, KL Div: 3177.7595\n",
      "Epoch[11/15], Step [140/469], Reconst Loss: 10356.1973, KL Div: 3276.1516\n",
      "Epoch[11/15], Step [150/469], Reconst Loss: 10320.5781, KL Div: 3178.0066\n",
      "Epoch[11/15], Step [160/469], Reconst Loss: 9765.6699, KL Div: 3138.8599\n",
      "Epoch[11/15], Step [170/469], Reconst Loss: 10203.3193, KL Div: 3234.7439\n",
      "Epoch[11/15], Step [180/469], Reconst Loss: 10360.1875, KL Div: 3175.5408\n",
      "Epoch[11/15], Step [190/469], Reconst Loss: 10554.3672, KL Div: 3311.4351\n",
      "Epoch[11/15], Step [200/469], Reconst Loss: 9895.7812, KL Div: 3150.3828\n",
      "Epoch[11/15], Step [210/469], Reconst Loss: 10032.1260, KL Div: 3167.3931\n",
      "Epoch[11/15], Step [220/469], Reconst Loss: 10313.4141, KL Div: 3157.3123\n",
      "Epoch[11/15], Step [230/469], Reconst Loss: 10531.3086, KL Div: 3234.5913\n",
      "Epoch[11/15], Step [240/469], Reconst Loss: 10701.8203, KL Div: 3345.6272\n",
      "Epoch[11/15], Step [250/469], Reconst Loss: 10514.9795, KL Div: 3351.1265\n",
      "Epoch[11/15], Step [260/469], Reconst Loss: 10625.3203, KL Div: 3226.2478\n",
      "Epoch[11/15], Step [270/469], Reconst Loss: 9996.0117, KL Div: 3284.3965\n",
      "Epoch[11/15], Step [280/469], Reconst Loss: 10789.8594, KL Div: 3338.1792\n",
      "Epoch[11/15], Step [290/469], Reconst Loss: 10232.1426, KL Div: 3147.2742\n",
      "Epoch[11/15], Step [300/469], Reconst Loss: 10027.0186, KL Div: 3210.3328\n",
      "Epoch[11/15], Step [310/469], Reconst Loss: 10293.7852, KL Div: 3324.8330\n",
      "Epoch[11/15], Step [320/469], Reconst Loss: 9771.7559, KL Div: 3169.6880\n",
      "Epoch[11/15], Step [330/469], Reconst Loss: 9735.2529, KL Div: 3021.3750\n",
      "Epoch[11/15], Step [340/469], Reconst Loss: 10176.0908, KL Div: 3316.9365\n",
      "Epoch[11/15], Step [350/469], Reconst Loss: 9612.6064, KL Div: 3083.9146\n",
      "Epoch[11/15], Step [360/469], Reconst Loss: 10277.1113, KL Div: 3271.2363\n",
      "Epoch[11/15], Step [370/469], Reconst Loss: 10317.8506, KL Div: 3240.6514\n",
      "Epoch[11/15], Step [380/469], Reconst Loss: 10267.7158, KL Div: 3217.7007\n",
      "Epoch[11/15], Step [390/469], Reconst Loss: 10244.7559, KL Div: 3338.0164\n",
      "Epoch[11/15], Step [400/469], Reconst Loss: 10436.7051, KL Div: 3227.2969\n",
      "Epoch[11/15], Step [410/469], Reconst Loss: 10438.9883, KL Div: 3246.6560\n",
      "Epoch[11/15], Step [420/469], Reconst Loss: 10053.3027, KL Div: 3335.1438\n",
      "Epoch[11/15], Step [430/469], Reconst Loss: 10023.4238, KL Div: 3109.7109\n",
      "Epoch[11/15], Step [440/469], Reconst Loss: 10427.7148, KL Div: 3281.5884\n",
      "Epoch[11/15], Step [450/469], Reconst Loss: 10516.5420, KL Div: 3218.3716\n",
      "Epoch[11/15], Step [460/469], Reconst Loss: 10843.3516, KL Div: 3205.7432\n",
      "Epoch[12/15], Step [10/469], Reconst Loss: 10315.4297, KL Div: 3217.4231\n",
      "Epoch[12/15], Step [20/469], Reconst Loss: 10263.4043, KL Div: 3201.7261\n",
      "Epoch[12/15], Step [30/469], Reconst Loss: 10081.8848, KL Div: 3155.7700\n",
      "Epoch[12/15], Step [40/469], Reconst Loss: 10030.6230, KL Div: 3144.8613\n",
      "Epoch[12/15], Step [50/469], Reconst Loss: 10190.1699, KL Div: 3151.1045\n",
      "Epoch[12/15], Step [60/469], Reconst Loss: 9782.0283, KL Div: 3145.7998\n",
      "Epoch[12/15], Step [70/469], Reconst Loss: 10231.0000, KL Div: 3144.1592\n",
      "Epoch[12/15], Step [80/469], Reconst Loss: 10028.6943, KL Div: 3266.1982\n",
      "Epoch[12/15], Step [90/469], Reconst Loss: 10452.9355, KL Div: 3213.8853\n",
      "Epoch[12/15], Step [100/469], Reconst Loss: 9900.2656, KL Div: 3293.5474\n",
      "Epoch[12/15], Step [110/469], Reconst Loss: 10188.3408, KL Div: 3234.0815\n",
      "Epoch[12/15], Step [120/469], Reconst Loss: 10504.1484, KL Div: 3224.1970\n",
      "Epoch[12/15], Step [130/469], Reconst Loss: 10404.3789, KL Div: 3317.6660\n",
      "Epoch[12/15], Step [140/469], Reconst Loss: 10185.7305, KL Div: 3101.0327\n",
      "Epoch[12/15], Step [150/469], Reconst Loss: 10149.1260, KL Div: 3250.0393\n",
      "Epoch[12/15], Step [160/469], Reconst Loss: 10229.3477, KL Div: 3110.4790\n",
      "Epoch[12/15], Step [170/469], Reconst Loss: 10155.5938, KL Div: 3215.1763\n",
      "Epoch[12/15], Step [180/469], Reconst Loss: 10165.5781, KL Div: 3306.8672\n",
      "Epoch[12/15], Step [190/469], Reconst Loss: 10843.0410, KL Div: 3260.0205\n",
      "Epoch[12/15], Step [200/469], Reconst Loss: 10189.6133, KL Div: 3336.1943\n",
      "Epoch[12/15], Step [210/469], Reconst Loss: 10273.0225, KL Div: 3178.0166\n",
      "Epoch[12/15], Step [220/469], Reconst Loss: 10018.1543, KL Div: 3248.2847\n",
      "Epoch[12/15], Step [230/469], Reconst Loss: 10558.6953, KL Div: 3284.4800\n",
      "Epoch[12/15], Step [240/469], Reconst Loss: 10401.6357, KL Div: 3315.6228\n",
      "Epoch[12/15], Step [250/469], Reconst Loss: 10094.9707, KL Div: 3145.4028\n",
      "Epoch[12/15], Step [260/469], Reconst Loss: 10507.0137, KL Div: 3275.0005\n",
      "Epoch[12/15], Step [270/469], Reconst Loss: 10266.0176, KL Div: 3239.2520\n",
      "Epoch[12/15], Step [280/469], Reconst Loss: 10744.6934, KL Div: 3267.0449\n",
      "Epoch[12/15], Step [290/469], Reconst Loss: 9563.3535, KL Div: 3092.3896\n",
      "Epoch[12/15], Step [300/469], Reconst Loss: 10774.5312, KL Div: 3187.5095\n",
      "Epoch[12/15], Step [310/469], Reconst Loss: 10556.4033, KL Div: 3210.4927\n",
      "Epoch[12/15], Step [320/469], Reconst Loss: 10296.0234, KL Div: 3161.5630\n",
      "Epoch[12/15], Step [330/469], Reconst Loss: 10333.6641, KL Div: 3250.6743\n",
      "Epoch[12/15], Step [340/469], Reconst Loss: 10400.5859, KL Div: 3272.7070\n",
      "Epoch[12/15], Step [350/469], Reconst Loss: 10516.1113, KL Div: 3281.1375\n",
      "Epoch[12/15], Step [360/469], Reconst Loss: 9731.6270, KL Div: 3107.7803\n",
      "Epoch[12/15], Step [370/469], Reconst Loss: 10215.5762, KL Div: 3098.0601\n",
      "Epoch[12/15], Step [380/469], Reconst Loss: 10171.5352, KL Div: 3327.1782\n",
      "Epoch[12/15], Step [390/469], Reconst Loss: 10856.8926, KL Div: 3277.4968\n",
      "Epoch[12/15], Step [400/469], Reconst Loss: 10093.9072, KL Div: 3268.4602\n",
      "Epoch[12/15], Step [410/469], Reconst Loss: 10555.5010, KL Div: 3283.6724\n",
      "Epoch[12/15], Step [420/469], Reconst Loss: 10305.7129, KL Div: 3127.9333\n",
      "Epoch[12/15], Step [430/469], Reconst Loss: 10650.2559, KL Div: 3289.2612\n",
      "Epoch[12/15], Step [440/469], Reconst Loss: 10008.4551, KL Div: 3212.1633\n",
      "Epoch[12/15], Step [450/469], Reconst Loss: 9895.5010, KL Div: 3149.4429\n",
      "Epoch[12/15], Step [460/469], Reconst Loss: 9837.4785, KL Div: 3113.8584\n",
      "Epoch[13/15], Step [10/469], Reconst Loss: 10539.0918, KL Div: 3168.7119\n",
      "Epoch[13/15], Step [20/469], Reconst Loss: 10118.6680, KL Div: 3170.8174\n",
      "Epoch[13/15], Step [30/469], Reconst Loss: 10199.3496, KL Div: 3149.7949\n",
      "Epoch[13/15], Step [40/469], Reconst Loss: 9828.5508, KL Div: 3156.4004\n",
      "Epoch[13/15], Step [50/469], Reconst Loss: 10307.1777, KL Div: 3264.7998\n",
      "Epoch[13/15], Step [60/469], Reconst Loss: 10811.4102, KL Div: 3319.5796\n",
      "Epoch[13/15], Step [70/469], Reconst Loss: 10165.8652, KL Div: 3115.1860\n",
      "Epoch[13/15], Step [80/469], Reconst Loss: 10274.4424, KL Div: 3212.9355\n",
      "Epoch[13/15], Step [90/469], Reconst Loss: 10383.2939, KL Div: 3174.0393\n",
      "Epoch[13/15], Step [100/469], Reconst Loss: 10165.0156, KL Div: 3186.1265\n",
      "Epoch[13/15], Step [110/469], Reconst Loss: 10452.3008, KL Div: 3209.5376\n",
      "Epoch[13/15], Step [120/469], Reconst Loss: 10092.6211, KL Div: 3299.6804\n",
      "Epoch[13/15], Step [130/469], Reconst Loss: 10235.1982, KL Div: 3183.6860\n",
      "Epoch[13/15], Step [140/469], Reconst Loss: 10175.9297, KL Div: 3174.3330\n",
      "Epoch[13/15], Step [150/469], Reconst Loss: 10070.6719, KL Div: 3277.4456\n",
      "Epoch[13/15], Step [160/469], Reconst Loss: 10056.8848, KL Div: 3242.4800\n",
      "Epoch[13/15], Step [170/469], Reconst Loss: 10183.9072, KL Div: 3190.4937\n",
      "Epoch[13/15], Step [180/469], Reconst Loss: 10022.8984, KL Div: 3246.0933\n",
      "Epoch[13/15], Step [190/469], Reconst Loss: 10113.4473, KL Div: 3240.1226\n",
      "Epoch[13/15], Step [200/469], Reconst Loss: 9838.0117, KL Div: 3129.5293\n",
      "Epoch[13/15], Step [210/469], Reconst Loss: 10125.5967, KL Div: 3280.2151\n",
      "Epoch[13/15], Step [220/469], Reconst Loss: 10154.5879, KL Div: 3265.0229\n",
      "Epoch[13/15], Step [230/469], Reconst Loss: 10086.5020, KL Div: 3089.8757\n",
      "Epoch[13/15], Step [240/469], Reconst Loss: 10153.3984, KL Div: 3244.3108\n",
      "Epoch[13/15], Step [250/469], Reconst Loss: 10097.9512, KL Div: 3260.2173\n",
      "Epoch[13/15], Step [260/469], Reconst Loss: 9820.0293, KL Div: 3128.0918\n",
      "Epoch[13/15], Step [270/469], Reconst Loss: 10325.2881, KL Div: 3279.9429\n",
      "Epoch[13/15], Step [280/469], Reconst Loss: 10478.0078, KL Div: 3256.3132\n",
      "Epoch[13/15], Step [290/469], Reconst Loss: 10488.7314, KL Div: 3324.1836\n",
      "Epoch[13/15], Step [300/469], Reconst Loss: 10441.2393, KL Div: 3250.2996\n",
      "Epoch[13/15], Step [310/469], Reconst Loss: 10232.6621, KL Div: 3238.0610\n",
      "Epoch[13/15], Step [320/469], Reconst Loss: 10549.3984, KL Div: 3242.1143\n",
      "Epoch[13/15], Step [330/469], Reconst Loss: 10748.7051, KL Div: 3401.8206\n",
      "Epoch[13/15], Step [340/469], Reconst Loss: 10357.9160, KL Div: 3226.0864\n",
      "Epoch[13/15], Step [350/469], Reconst Loss: 9834.7402, KL Div: 3212.7473\n",
      "Epoch[13/15], Step [360/469], Reconst Loss: 10332.9297, KL Div: 3158.5776\n",
      "Epoch[13/15], Step [370/469], Reconst Loss: 10339.1016, KL Div: 3319.6868\n",
      "Epoch[13/15], Step [380/469], Reconst Loss: 10212.2314, KL Div: 3236.1138\n",
      "Epoch[13/15], Step [390/469], Reconst Loss: 10554.9629, KL Div: 3334.7739\n",
      "Epoch[13/15], Step [400/469], Reconst Loss: 10429.0928, KL Div: 3228.7979\n",
      "Epoch[13/15], Step [410/469], Reconst Loss: 9879.0293, KL Div: 3204.3921\n",
      "Epoch[13/15], Step [420/469], Reconst Loss: 10010.4023, KL Div: 3281.8345\n",
      "Epoch[13/15], Step [430/469], Reconst Loss: 10204.4297, KL Div: 3208.1313\n",
      "Epoch[13/15], Step [440/469], Reconst Loss: 10107.7344, KL Div: 3170.5608\n",
      "Epoch[13/15], Step [450/469], Reconst Loss: 10106.1875, KL Div: 3229.6465\n",
      "Epoch[13/15], Step [460/469], Reconst Loss: 10619.8125, KL Div: 3285.0386\n",
      "Epoch[14/15], Step [10/469], Reconst Loss: 10498.7012, KL Div: 3353.9243\n",
      "Epoch[14/15], Step [20/469], Reconst Loss: 10114.7617, KL Div: 3139.1270\n",
      "Epoch[14/15], Step [30/469], Reconst Loss: 10074.5977, KL Div: 3233.9783\n",
      "Epoch[14/15], Step [40/469], Reconst Loss: 10012.9238, KL Div: 3256.9607\n",
      "Epoch[14/15], Step [50/469], Reconst Loss: 9778.5684, KL Div: 3225.9912\n",
      "Epoch[14/15], Step [60/469], Reconst Loss: 10304.1387, KL Div: 3214.7935\n",
      "Epoch[14/15], Step [70/469], Reconst Loss: 10551.3740, KL Div: 3253.1929\n",
      "Epoch[14/15], Step [80/469], Reconst Loss: 10501.3633, KL Div: 3235.7871\n",
      "Epoch[14/15], Step [90/469], Reconst Loss: 10498.2305, KL Div: 3317.9272\n",
      "Epoch[14/15], Step [100/469], Reconst Loss: 10132.6279, KL Div: 3329.3423\n",
      "Epoch[14/15], Step [110/469], Reconst Loss: 10097.7373, KL Div: 3294.5088\n",
      "Epoch[14/15], Step [120/469], Reconst Loss: 10031.5156, KL Div: 3196.7097\n",
      "Epoch[14/15], Step [130/469], Reconst Loss: 9871.3906, KL Div: 3145.2739\n",
      "Epoch[14/15], Step [140/469], Reconst Loss: 10243.1553, KL Div: 3357.5276\n",
      "Epoch[14/15], Step [150/469], Reconst Loss: 10059.1426, KL Div: 3217.2100\n",
      "Epoch[14/15], Step [160/469], Reconst Loss: 10076.9863, KL Div: 3191.5625\n",
      "Epoch[14/15], Step [170/469], Reconst Loss: 10077.2676, KL Div: 3200.8359\n",
      "Epoch[14/15], Step [180/469], Reconst Loss: 9978.2256, KL Div: 3105.6758\n",
      "Epoch[14/15], Step [190/469], Reconst Loss: 10582.7754, KL Div: 3272.2642\n",
      "Epoch[14/15], Step [200/469], Reconst Loss: 10418.8340, KL Div: 3195.0791\n",
      "Epoch[14/15], Step [210/469], Reconst Loss: 10379.1250, KL Div: 3248.4790\n",
      "Epoch[14/15], Step [220/469], Reconst Loss: 10223.4160, KL Div: 3286.8955\n",
      "Epoch[14/15], Step [230/469], Reconst Loss: 10427.7217, KL Div: 3259.2827\n",
      "Epoch[14/15], Step [240/469], Reconst Loss: 10161.3809, KL Div: 3244.1323\n",
      "Epoch[14/15], Step [250/469], Reconst Loss: 10331.1973, KL Div: 3208.2087\n",
      "Epoch[14/15], Step [260/469], Reconst Loss: 10807.2520, KL Div: 3233.8481\n",
      "Epoch[14/15], Step [270/469], Reconst Loss: 9866.9043, KL Div: 3230.0725\n",
      "Epoch[14/15], Step [280/469], Reconst Loss: 9841.3760, KL Div: 3100.7437\n",
      "Epoch[14/15], Step [290/469], Reconst Loss: 10321.6543, KL Div: 3293.7078\n",
      "Epoch[14/15], Step [300/469], Reconst Loss: 10184.9766, KL Div: 3186.0967\n",
      "Epoch[14/15], Step [310/469], Reconst Loss: 10094.6113, KL Div: 3321.0049\n",
      "Epoch[14/15], Step [320/469], Reconst Loss: 10133.6738, KL Div: 3225.0408\n",
      "Epoch[14/15], Step [330/469], Reconst Loss: 10549.1279, KL Div: 3321.5518\n",
      "Epoch[14/15], Step [340/469], Reconst Loss: 9826.4463, KL Div: 3171.7283\n",
      "Epoch[14/15], Step [350/469], Reconst Loss: 10518.9980, KL Div: 3295.8477\n",
      "Epoch[14/15], Step [360/469], Reconst Loss: 10135.1816, KL Div: 3095.9270\n",
      "Epoch[14/15], Step [370/469], Reconst Loss: 10334.2256, KL Div: 3276.8672\n",
      "Epoch[14/15], Step [380/469], Reconst Loss: 10027.5830, KL Div: 3265.5527\n",
      "Epoch[14/15], Step [390/469], Reconst Loss: 10259.4541, KL Div: 3273.4624\n",
      "Epoch[14/15], Step [400/469], Reconst Loss: 10417.9971, KL Div: 3242.8809\n",
      "Epoch[14/15], Step [410/469], Reconst Loss: 10632.3379, KL Div: 3240.7485\n",
      "Epoch[14/15], Step [420/469], Reconst Loss: 10069.8594, KL Div: 3252.0825\n",
      "Epoch[14/15], Step [430/469], Reconst Loss: 9605.5078, KL Div: 3239.8491\n",
      "Epoch[14/15], Step [440/469], Reconst Loss: 9696.1895, KL Div: 3046.7632\n",
      "Epoch[14/15], Step [450/469], Reconst Loss: 10552.5352, KL Div: 3315.2251\n",
      "Epoch[14/15], Step [460/469], Reconst Loss: 10379.8252, KL Div: 3144.8748\n",
      "Epoch[15/15], Step [10/469], Reconst Loss: 10193.0557, KL Div: 3257.6138\n",
      "Epoch[15/15], Step [20/469], Reconst Loss: 10246.6113, KL Div: 3165.4399\n",
      "Epoch[15/15], Step [30/469], Reconst Loss: 9926.4639, KL Div: 3180.4624\n",
      "Epoch[15/15], Step [40/469], Reconst Loss: 10374.0371, KL Div: 3194.7979\n",
      "Epoch[15/15], Step [50/469], Reconst Loss: 10246.2891, KL Div: 3302.6492\n",
      "Epoch[15/15], Step [60/469], Reconst Loss: 10253.4863, KL Div: 3241.3291\n",
      "Epoch[15/15], Step [70/469], Reconst Loss: 10081.2217, KL Div: 3158.2651\n",
      "Epoch[15/15], Step [80/469], Reconst Loss: 10047.7637, KL Div: 3204.4077\n",
      "Epoch[15/15], Step [90/469], Reconst Loss: 9975.7578, KL Div: 3279.2808\n",
      "Epoch[15/15], Step [100/469], Reconst Loss: 10603.0684, KL Div: 3197.8149\n",
      "Epoch[15/15], Step [110/469], Reconst Loss: 10380.9121, KL Div: 3275.4036\n",
      "Epoch[15/15], Step [120/469], Reconst Loss: 10061.6133, KL Div: 3171.7585\n",
      "Epoch[15/15], Step [130/469], Reconst Loss: 10226.6758, KL Div: 3210.1226\n",
      "Epoch[15/15], Step [140/469], Reconst Loss: 9971.1641, KL Div: 3292.7715\n",
      "Epoch[15/15], Step [150/469], Reconst Loss: 10441.3770, KL Div: 3246.4912\n",
      "Epoch[15/15], Step [160/469], Reconst Loss: 10195.4854, KL Div: 3211.0366\n",
      "Epoch[15/15], Step [170/469], Reconst Loss: 10163.2031, KL Div: 3175.3694\n",
      "Epoch[15/15], Step [180/469], Reconst Loss: 9450.4463, KL Div: 3108.0474\n",
      "Epoch[15/15], Step [190/469], Reconst Loss: 10271.8564, KL Div: 3273.2739\n",
      "Epoch[15/15], Step [200/469], Reconst Loss: 9642.5449, KL Div: 3117.1023\n",
      "Epoch[15/15], Step [210/469], Reconst Loss: 10173.3066, KL Div: 3296.7710\n",
      "Epoch[15/15], Step [220/469], Reconst Loss: 10163.3145, KL Div: 3314.5698\n",
      "Epoch[15/15], Step [230/469], Reconst Loss: 10264.4775, KL Div: 3294.2480\n",
      "Epoch[15/15], Step [240/469], Reconst Loss: 10463.9531, KL Div: 3246.8767\n",
      "Epoch[15/15], Step [250/469], Reconst Loss: 9995.0215, KL Div: 3178.9387\n",
      "Epoch[15/15], Step [260/469], Reconst Loss: 10153.3691, KL Div: 3184.1230\n",
      "Epoch[15/15], Step [270/469], Reconst Loss: 10232.9033, KL Div: 3264.3735\n",
      "Epoch[15/15], Step [280/469], Reconst Loss: 10073.4424, KL Div: 3276.1064\n",
      "Epoch[15/15], Step [290/469], Reconst Loss: 10190.9600, KL Div: 3240.8252\n",
      "Epoch[15/15], Step [300/469], Reconst Loss: 10578.1602, KL Div: 3315.6343\n",
      "Epoch[15/15], Step [310/469], Reconst Loss: 10323.1855, KL Div: 3266.9976\n",
      "Epoch[15/15], Step [320/469], Reconst Loss: 9543.9785, KL Div: 3141.6035\n",
      "Epoch[15/15], Step [330/469], Reconst Loss: 10256.8613, KL Div: 3186.6401\n",
      "Epoch[15/15], Step [340/469], Reconst Loss: 9967.0410, KL Div: 3189.2058\n",
      "Epoch[15/15], Step [350/469], Reconst Loss: 10346.3340, KL Div: 3287.2996\n",
      "Epoch[15/15], Step [360/469], Reconst Loss: 9788.4746, KL Div: 3186.9634\n",
      "Epoch[15/15], Step [370/469], Reconst Loss: 10099.1953, KL Div: 3205.0737\n",
      "Epoch[15/15], Step [380/469], Reconst Loss: 9676.1992, KL Div: 3196.2002\n",
      "Epoch[15/15], Step [390/469], Reconst Loss: 10170.1816, KL Div: 3220.7007\n",
      "Epoch[15/15], Step [400/469], Reconst Loss: 10222.2471, KL Div: 3248.1113\n",
      "Epoch[15/15], Step [410/469], Reconst Loss: 9844.4248, KL Div: 3156.2263\n",
      "Epoch[15/15], Step [420/469], Reconst Loss: 10526.2148, KL Div: 3266.1963\n",
      "Epoch[15/15], Step [430/469], Reconst Loss: 10184.2012, KL Div: 3256.1396\n",
      "Epoch[15/15], Step [440/469], Reconst Loss: 10152.4805, KL Div: 3217.2817\n",
      "Epoch[15/15], Step [450/469], Reconst Loss: 10291.9395, KL Div: 3265.5007\n",
      "Epoch[15/15], Step [460/469], Reconst Loss: 10274.2500, KL Div: 3249.0786\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('python38': conda)"
  },
  "interpreter": {
   "hash": "87bde4b8ac899a866791947b85fa526e720fe9897752d0655688f577c9f6fa63"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}